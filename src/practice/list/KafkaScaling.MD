# Масштабирование Apache Kafka

В рамках текущей работы вам предстоит познакомиться с механикой масштабирования такого инструмента, как Apache Kafka. Для того, чтобы быть готовым, необходимо:
- Разобраться как создать Consumer и Producer в Kafka
- Разобраться с особенностями партиционирования в Kafka
- Настроить любой инструмент для нагрузочного тестирования


### Методические материалы
В рамках текущей работы необходимо сделать несколько последовательных шагов. Это лишь пример, работа является больше исследовательской, чем практически-методической

1. Необходимо подняться Apache Kafka и создать в ней топик с любым названием. Количество партиций в топике - 2
2. Необходимо написать producer, который отправляет в кафку сообщения. Producer должен быть реализован в виде веб-сервера (принимать POST-запрос и отправлять тело запроса в Kafka)
3. Написать consumer, который читает сообщение из топика и сохраняет его в любую базу
4. Создать consumer-group из 2 консьюмеров
5. При помощи Jmeter или любого другого инструмента для нагрузочного тестирования начать загружать продьюсер, увеличивая нагрузку постепенно
6. Замерять время, которое необходимо системе для обработки такого количества запросов
7. Увеличить количество консьюмеров и партиций вдвое (тут можно поиграть с цифрами)
8. Повторить пункт 5-7 несколько раз 

Обратить внимания в каком месте происходит деградация производительности

### Дополнительный материал для чтения
- https://www.baeldung.com/kafka-topics-partitions
- https://habr.com/ru/companies/sbermarket/articles/738634/
- https://www.tutorialspoint.com/jmeter/jmeter_quick_guide.htm